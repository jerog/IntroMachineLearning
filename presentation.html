<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="James Rogers" />


<title>Machine Learning analysis of Human Activity Recognition data</title>

<script src="presentation_files/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="presentation_files/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="presentation_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="presentation_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="presentation_files/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="presentation_files/navigation-1.1/tabsets.js"></script>
<link href="presentation_files/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="presentation_files/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>



<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Machine Learning analysis of Human Activity Recognition data</h1>
<h4 class="author"><em>James Rogers</em></h4>
<h4 class="date"><em>1/27/2018</em></h4>

</div>


<div id="data-characterization" class="section level2">
<h2>Data characterization</h2>
<pre class="r"><code>if(!file.exists(&quot;pml-training.csv&quot;)) {
  download.file(&quot;https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv&quot;, &quot;pml-training.csv&quot;)
}
trainingRaw &lt;- read.csv(&quot;pml-training.csv&quot;)</code></pre>
<p>The data represent readings taken from Human Activity Recognition (HAR) devices during the execution of five different weightlifting motions, classified as A, B, C, D, or E. (Data published at <a href="http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har" class="uri">http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har</a>.) The motions were executed by six different subjects in 858 different instances (labeled as “windows”). Each window consists of up to 38 snapshots of readings from different HAR devices. A single observation in the data table consists of one snapshot. The task is to be able to identify the motion being performed from a single snapshot.</p>
<p>The 160 variables recorded include the subject name, the activity class, 6 variables for labeling, including timestamp and windows. The rest consist of instrumental readings at each snapshot and a series of per-window data aggregates.</p>
</div>
<div id="data-processing" class="section level2">
<h2>Data processing</h2>
<p>Because the goal is to identify from a single snapshot, the aggregate data was removed. Labels and timestamps were removed as irrelevant to the outcome; window number is a perfect predictor of activity class but was removed in the spirit of the exercise.</p>
<pre class="r"><code>colsToEliminate &lt;- c(1, 3:7, grep(&quot;^(kurtosis|skewness|max|min|amplitude|avg|stddev|var)&quot;,colnames(trainingRaw)))
trainingStreamlined &lt;- trainingRaw[, -colsToEliminate]</code></pre>
<p>A validation set was split off from the training set.</p>
<pre class="r"><code>suppressMessages(library(dplyr))
suppressMessages(library(caret))
set.seed(121212)
trainIndex &lt;- createDataPartition(trainingStreamlined$classe, p = .8, list = FALSE, times = 1)
training = trainingStreamlined[trainIndex,]
validation = trainingStreamlined[-trainIndex,]</code></pre>
</div>
<div id="exploratory-analysis" class="section level2">
<h2>Exploratory analysis</h2>
<p>Certain variables seem correlated with class but also vary strongly according to the experimental subject performing the movement (column “user_name”).</p>
<pre class="r"><code>par(mfrow=c(1,2))
plot(training$accel_belt_z, training$classe, col = training$user_name)
plot(training$pitch_belt, training$classe, col = training$user_name)</code></pre>
<p><img src="presentation_files/figure-html/prelim_1-1.png" width="672" /></p>
<p>In fact, a quick primary component analysis displays a slight amount of separation for some activity classes but a much more dramatic separation by subject. Clearly this dataset is very subject-specific.</p>
<pre class="r"><code>pca &lt;- preProcess(training, method=c(&quot;pca&quot;,&quot;nzv&quot;))
pcaTraining&lt;-predict(pca, newdata = training)</code></pre>
<pre class="r"><code>par(mfrow=c(1,2))
plot(pcaTraining$PC1, pcaTraining$PC2, col = training$classe, main=&quot;Colored by activity class&quot;)
plot(pcaTraining$PC1, pcaTraining$PC2, col = training$user_name, main=&quot;Colored by subject&quot;)</code></pre>
<p><img src="presentation_files/figure-html/pca_plot-1.png" width="672" /></p>
</div>
<div id="fitting-a-tree-model" class="section level2">
<h2>Fitting a tree model</h2>
<div id="rpart-on-the-entire-set" class="section level3">
<h3>rpart on the entire set</h3>
<p>To show the effect of subject on the data note the difference between a random partition of the entire training data set, optimized on maximum tree depth and yielding an in-sample accuracy of 72%:</p>
<pre class="r"><code>ctrl1 &lt;- trainControl(method=&quot;repeatedcv&quot;, number = 10, repeats = 5, classProbs = TRUE)
set.seed(343434)
modelGeneralRpart2&lt;-train(classe ~ ., data = training, method=&quot;rpart2&quot;, trControl = ctrl1, tuneLength = 20)
modelGeneralRpart2$bestTune[[&quot;maxdepth&quot;]]</code></pre>
<pre><code>## [1] 24</code></pre>
<pre class="r"><code>(confusionMatrix(predict(modelGeneralRpart2), training$classe))[[&quot;overall&quot;]][[&quot;Accuracy&quot;]]</code></pre>
<pre><code>## [1] 0.7215109</code></pre>
</div>
<div id="rpart-on-subject-subset" class="section level3">
<h3>rpart on subject subset</h3>
<p>… contrasted with the accuracy of six separate models created by the same method on the training data split by subject, which result in an in-sample accuracy of 92%.</p>
<pre class="r"><code>rpart2PerSubject &lt;- function(x) {
  trainingSubset &lt;- training[training$user_name == x,]
  modelSpecificRpart2 &lt;- train(classe ~ ., data = trainingSubset, method=&quot;rpart2&quot;, trControl = ctrl1, tuneLength = 20)
  list(maxdepth = modelSpecificRpart2$bestTune[[&quot;maxdepth&quot;]],
       accuracy = (confusionMatrix(predict(modelSpecificRpart2), trainingSubset$classe))[[&quot;overall&quot;]][[&quot;Accuracy&quot;]],
       samplesize = nrow(trainingSubset))
}

# In-sample accuracy for each subject-specific tree
set.seed(565656)
specificModelData &lt;- suppressMessages(sapply(levels(training$user_name), rpart2PerSubject))</code></pre>
<pre><code>## note: only 18 possible values of the max tree depth from the initial fit.
##  Truncating the grid to 18 .
## 
## note: only 19 possible values of the max tree depth from the initial fit.
##  Truncating the grid to 19 .
## 
## note: only 11 possible values of the max tree depth from the initial fit.
##  Truncating the grid to 11 .
## 
## note: only 18 possible values of the max tree depth from the initial fit.
##  Truncating the grid to 18 .
## 
## note: only 18 possible values of the max tree depth from the initial fit.
##  Truncating the grid to 18 .
## 
## note: only 18 possible values of the max tree depth from the initial fit.
##  Truncating the grid to 18 .</code></pre>
<pre class="r"><code>specificModelData</code></pre>
<pre><code>##            adelmo    carlitos  charles  eurico    jeremy    pedro    
## maxdepth   13        14        5        14        17        15       
## accuracy   0.9175024 0.9210421 0.960452 0.9115479 0.8949672 0.9213162
## samplesize 3091      2495      2832     2442      2742      2097</code></pre>
<pre class="r"><code># Weighted in-sample accuracy over the entire training set
weightedAccuracy &lt;- (sapply(1:6, function(x) {l&lt;-specificModelData[, x]; l[[&quot;accuracy&quot;]] * l[[&quot;samplesize&quot;]]}) %&gt;% sum()) / nrow(training)
weightedAccuracy</code></pre>
<pre><code>## [1] 0.92146</code></pre>
<p>This model might be selected for maximum interpretability but would be impossible to apply to new users.</p>
</div>
</div>
<div id="final-model" class="section level2">
<h2>Final model</h2>
<p>For maximum accuracy, a random forest model, though time-consuming, proved to be the best choice and did not require the data to be split by subject. The final model achieved a 100% in-sample accuracy and an out-of-sample accuracy (against the validation set) of over 99.5%.</p>
<pre class="r"><code>set.seed(787878)
fitRf &lt;- train(classe ~ ., data = training, method=&quot;rf&quot;, tuneLength = 10)

# In-sample accuracy
confusionMatrix(predict(fitRf), training$classe)[[&quot;overall&quot;]][[&quot;Accuracy&quot;]]</code></pre>
<pre><code>## [1] 1</code></pre>
<pre class="r"><code># Out-of-sample accuracy
confusionMatrix(predict(fitRf, newdata = validation), validation$classe)[[&quot;overall&quot;]][[&quot;Accuracy&quot;]]</code></pre>
<pre><code>## [1] 0.9959215</code></pre>
<pre class="r"><code># Best value for mtry, as determined by caret
fitRf$bestTune[[&quot;mtry&quot;]]</code></pre>
<pre><code>## [1] 8</code></pre>
<pre class="r"><code>plot(fitRf)</code></pre>
<p><img src="presentation_files/figure-html/rf-1.png" width="672" /></p>
<p>Caret tested 10 values of mtry, using the caret default of 25-fold resampling, to determine the best model fit for random forest and arrived at 8, close to the default value of sqrt(number of predictors) provided for classification problems by the randomForest library. However, the final fit cannot be called universally applicable until tested against device readings from users other than the six subjects of this study.</p>
</div>
<div id="predicting-for-the-final-test-set" class="section level2">
<h2>Predicting for the final test set</h2>
<p>R code to download the final test set and run the prediction using the random forest model is shown but not evaluated.</p>
<pre class="r"><code>if(!file.exists(&quot;pml-testing.csv&quot;)) {
  download.file(&quot;https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv&quot;, &quot;pml-testing.csv&quot;)
}
testingRaw &lt;- read.csv(&quot;pml-testing.csv&quot;)
testingResults &lt;- predict(fitRf, newdata = testingRaw)
testingResults</code></pre>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
